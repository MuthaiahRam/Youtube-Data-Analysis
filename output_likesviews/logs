[cloudera@quickstart ~]$ spark-submit --master local[*] --deploy-mode client --class com.cs267.youtube.util.LikesViewsDriver /home/cloudera/Desktop/youtube-new/Youtube.jar /user/cloudera/project/input/ /user/cloudera/project/output
18/04/08 16:56:09 INFO spark.SparkContext: Running Spark version 1.6.0
18/04/08 16:56:11 INFO spark.SecurityManager: Changing view acls to: cloudera
18/04/08 16:56:11 INFO spark.SecurityManager: Changing modify acls to: cloudera
18/04/08 16:56:11 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(cloudera); users with modify permissions: Set(cloudera)
18/04/08 16:56:12 INFO util.Utils: Successfully started service 'sparkDriver' on port 47231.
18/04/08 16:56:13 INFO slf4j.Slf4jLogger: Slf4jLogger started
18/04/08 16:56:13 INFO Remoting: Starting remoting
18/04/08 16:56:13 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.0.2.15:37523]
18/04/08 16:56:13 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@10.0.2.15:37523]
18/04/08 16:56:13 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 37523.
18/04/08 16:56:14 INFO spark.SparkEnv: Registering MapOutputTracker
18/04/08 16:56:14 INFO spark.SparkEnv: Registering BlockManagerMaster
18/04/08 16:56:14 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-bb115cd2-c4a4-428e-8d87-290ea273d9e2
18/04/08 16:56:14 INFO storage.MemoryStore: MemoryStore started with capacity 530.3 MB
18/04/08 16:56:14 INFO spark.SparkEnv: Registering OutputCommitCoordinator
18/04/08 16:56:15 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
18/04/08 16:56:15 INFO ui.SparkUI: Started SparkUI at http://10.0.2.15:4040
18/04/08 16:56:15 INFO spark.SparkContext: Added JAR file:/home/cloudera/Desktop/youtube-new/Youtube.jar at spark://10.0.2.15:47231/jars/Youtube.jar with timestamp 1523231775409
18/04/08 16:56:15 INFO executor.Executor: Starting executor ID driver on host localhost
18/04/08 16:56:16 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58709.
18/04/08 16:56:16 INFO netty.NettyBlockTransferService: Server created on 58709
18/04/08 16:56:16 INFO storage.BlockManager: external shuffle service port = 7337
18/04/08 16:56:16 INFO storage.BlockManagerMaster: Trying to register BlockManager
18/04/08 16:56:16 INFO storage.BlockManagerMasterEndpoint: Registering block manager localhost:58709 with 530.3 MB RAM, BlockManagerId(driver, localhost, 58709)
18/04/08 16:56:16 INFO storage.BlockManagerMaster: Registered BlockManager
18/04/08 16:56:19 INFO scheduler.EventLoggingListener: Logging events to hdfs://quickstart.cloudera:8020/user/spark/applicationHistory/local-1523231775684
18/04/08 16:56:19 INFO spark.SparkContext: Registered listener com.cloudera.spark.lineage.ClouderaNavigatorListener
18/04/08 16:56:21 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 209.1 KB, free 530.1 MB)
18/04/08 16:56:21 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.3 KB, free 530.1 MB)
18/04/08 16:56:21 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58709 (size: 25.3 KB, free: 530.3 MB)
18/04/08 16:56:21 INFO spark.SparkContext: Created broadcast 0 from textFile at LikesViewsDriver.java:25
18/04/08 16:56:22 INFO mapred.FileInputFormat: Total input paths to process : 5
18/04/08 16:56:22 INFO spark.SparkContext: Starting job: first at LikesViewsDriver.java:26
18/04/08 16:56:23 INFO scheduler.DAGScheduler: Got job 0 (first at LikesViewsDriver.java:26) with 1 output partitions
18/04/08 16:56:23 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (first at LikesViewsDriver.java:26)
18/04/08 16:56:23 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/04/08 16:56:23 INFO scheduler.DAGScheduler: Missing parents: List()
18/04/08 16:56:23 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (/user/cloudera/project/input/ MapPartitionsRDD[1] at textFile at LikesViewsDriver.java:25), which has no missing parents
18/04/08 16:56:23 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 530.0 MB)
18/04/08 16:56:23 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1847.0 B, free 530.0 MB)
18/04/08 16:56:23 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58709 (size: 1847.0 B, free: 530.3 MB)
18/04/08 16:56:23 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1004
18/04/08 16:56:23 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (/user/cloudera/project/input/ MapPartitionsRDD[1] at textFile at LikesViewsDriver.java:25) (first 15 tasks are for partitions Vector(0))
18/04/08 16:56:23 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/04/08 16:56:23 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 2228 bytes)
18/04/08 16:56:23 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
18/04/08 16:56:23 INFO executor.Executor: Fetching spark://10.0.2.15:47231/jars/Youtube.jar with timestamp 1523231775409
18/04/08 16:56:24 INFO spark.ExecutorAllocationManager: New executor driver has registered (new total is 1)
18/04/08 16:56:24 INFO util.Utils: Fetching spark://10.0.2.15:47231/jars/Youtube.jar to /tmp/spark-6bdf5304-d1ff-409f-aa20-3e92f39e0106/userFiles-cdf7fa08-f387-41db-9cbb-b57f72e085dc/fetchFileTemp4514711692427249938.tmp
18/04/08 16:56:24 INFO executor.Executor: Adding file:/tmp/spark-6bdf5304-d1ff-409f-aa20-3e92f39e0106/userFiles-cdf7fa08-f387-41db-9cbb-b57f72e085dc/Youtube.jar to class loader
18/04/08 16:56:25 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/project/input/CAvideos-csv.csv:0+43953781
18/04/08 16:56:25 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
18/04/08 16:56:25 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
18/04/08 16:56:25 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
18/04/08 16:56:25 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
18/04/08 16:56:25 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
18/04/08 16:56:25 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 2217 bytes result sent to driver
18/04/08 16:56:25 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1707 ms on localhost (executor driver) (1/1)
18/04/08 16:56:25 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/04/08 16:56:25 INFO scheduler.DAGScheduler: ResultStage 0 (first at LikesViewsDriver.java:26) finished in 1.834 s
18/04/08 16:56:25 INFO scheduler.DAGScheduler: Job 0 finished: first at LikesViewsDriver.java:26, took 2.634442 s
18/04/08 16:56:25 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/04/08 16:56:25 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/04/08 16:56:26 INFO spark.SparkContext: Starting job: saveAsTextFile at LikesViewsDriver.java:37
18/04/08 16:56:26 INFO scheduler.DAGScheduler: Got job 1 (saveAsTextFile at LikesViewsDriver.java:37) with 5 output partitions
18/04/08 16:56:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsTextFile at LikesViewsDriver.java:37)
18/04/08 16:56:26 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/04/08 16:56:26 INFO scheduler.DAGScheduler: Missing parents: List()
18/04/08 16:56:26 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at saveAsTextFile at LikesViewsDriver.java:37), which has no missing parents
18/04/08 16:56:27 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 80.0 KB, free 530.0 MB)
18/04/08 16:56:27 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 29.1 KB, free 529.9 MB)
18/04/08 16:56:27 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58709 (size: 29.1 KB, free: 530.2 MB)
18/04/08 16:56:27 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004
18/04/08 16:56:27 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at saveAsTextFile at LikesViewsDriver.java:37) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/08 16:56:27 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
18/04/08 16:56:27 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 2228 bytes)
18/04/08 16:56:27 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, ANY, 2228 bytes)
18/04/08 16:56:27 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1)
18/04/08 16:56:27 INFO executor.Executor: Running task 1.0 in stage 1.0 (TID 2)
18/04/08 16:56:27 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/project/input/CAvideos-csv.csv:0+43953781
18/04/08 16:56:27 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/project/input/DEvideos-csv.csv:0+43594992
18/04/08 16:56:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/04/08 16:56:27 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/04/08 16:56:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/04/08 16:56:27 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/04/08 16:56:28 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/08 16:56:28 WARN spark.ExecutorAllocationManager: Unable to reach the cluster manager to request 2 total executors!
18/04/08 16:56:29 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/08 16:56:29 WARN spark.ExecutorAllocationManager: Unable to reach the cluster manager to request 3 total executors!
18/04/08 16:56:30 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/08 16:56:30 WARN spark.ExecutorAllocationManager: Unable to reach the cluster manager to request 4 total executors!
18/04/08 16:56:31 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/08 16:56:31 WARN spark.ExecutorAllocationManager: Unable to reach the cluster manager to request 5 total executors!
18/04/08 16:56:39 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on localhost:58709 in memory (size: 1847.0 B, free: 530.2 MB)
18/04/08 16:56:39 INFO spark.ContextCleaner: Cleaned accumulator 1
18/04/08 16:57:45 INFO output.FileOutputCommitter: Saved output of task 'attempt_201804081656_0001_m_000001_2' to hdfs://quickstart.cloudera:8020/user/cloudera/project/output_likesviews/_temporary/0/task_201804081656_0001_m_000001
18/04/08 16:57:45 INFO mapred.SparkHadoopMapRedUtil: attempt_201804081656_0001_m_000001_2: Committed
18/04/08 16:57:45 INFO executor.Executor: Finished task 1.0 in stage 1.0 (TID 2). 2350 bytes result sent to driver
18/04/08 16:57:45 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, ANY, 2228 bytes)
18/04/08 16:57:45 INFO executor.Executor: Running task 2.0 in stage 1.0 (TID 3)
18/04/08 16:57:45 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 78501 ms on localhost (executor driver) (1/5)
18/04/08 16:57:45 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/08 16:57:45 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/project/input/FRvideos-csv.csv:0+34652058
18/04/08 16:57:45 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/04/08 16:57:45 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/04/08 16:57:50 INFO output.FileOutputCommitter: Saved output of task 'attempt_201804081656_0001_m_000000_1' to hdfs://quickstart.cloudera:8020/user/cloudera/project/output_likesviews/_temporary/0/task_201804081656_0001_m_000000
18/04/08 16:57:50 INFO mapred.SparkHadoopMapRedUtil: attempt_201804081656_0001_m_000000_1: Committed
18/04/08 16:57:50 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 2360 bytes result sent to driver
18/04/08 16:57:50 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, ANY, 2228 bytes)
18/04/08 16:57:50 INFO executor.Executor: Running task 3.0 in stage 1.0 (TID 4)
18/04/08 16:57:50 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 83297 ms on localhost (executor driver) (2/5)
18/04/08 16:57:50 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/08 16:57:50 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/project/input/GBvideos-csv.csv:0+38970381
18/04/08 16:57:50 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/04/08 16:57:50 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/04/08 16:58:50 INFO output.FileOutputCommitter: Saved output of task 'attempt_201804081656_0001_m_000002_3' to hdfs://quickstart.cloudera:8020/user/cloudera/project/output_likesviews/_temporary/0/task_201804081656_0001_m_000002
18/04/08 16:58:50 INFO mapred.SparkHadoopMapRedUtil: attempt_201804081656_0001_m_000002_3: Committed
18/04/08 16:58:50 INFO executor.Executor: Finished task 2.0 in stage 1.0 (TID 3). 2360 bytes result sent to driver
18/04/08 16:58:50 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5, localhost, executor driver, partition 4, ANY, 2228 bytes)
18/04/08 16:58:50 INFO executor.Executor: Running task 4.0 in stage 1.0 (TID 5)
18/04/08 16:58:50 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 65215 ms on localhost (executor driver) (3/5)
18/04/08 16:58:51 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/08 16:58:51 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/project/input/USvideos-csv.csv:0+42174771
18/04/08 16:58:51 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/04/08 16:58:51 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/04/08 16:59:09 INFO output.FileOutputCommitter: Saved output of task 'attempt_201804081656_0001_m_000003_4' to hdfs://quickstart.cloudera:8020/user/cloudera/project/output_likesviews/_temporary/0/task_201804081656_0001_m_000003
18/04/08 16:59:09 INFO mapred.SparkHadoopMapRedUtil: attempt_201804081656_0001_m_000003_4: Committed
18/04/08 16:59:09 INFO executor.Executor: Finished task 3.0 in stage 1.0 (TID 4). 2360 bytes result sent to driver
18/04/08 16:59:09 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 78525 ms on localhost (executor driver) (4/5)
18/04/08 16:59:09 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/08 17:00:01 INFO output.FileOutputCommitter: Saved output of task 'attempt_201804081656_0001_m_000004_5' to hdfs://quickstart.cloudera:8020/user/cloudera/project/output_likesviews/_temporary/0/task_201804081656_0001_m_000004
18/04/08 17:00:01 INFO mapred.SparkHadoopMapRedUtil: attempt_201804081656_0001_m_000004_5: Committed
18/04/08 17:00:01 INFO executor.Executor: Finished task 4.0 in stage 1.0 (TID 5). 2360 bytes result sent to driver
18/04/08 17:00:01 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsTextFile at LikesViewsDriver.java:37) finished in 213.861 s
18/04/08 17:00:01 INFO scheduler.DAGScheduler: Job 1 finished: saveAsTextFile at LikesViewsDriver.java:37, took 214.296835 s
18/04/08 17:00:01 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 70331 ms on localhost (executor driver) (5/5)
18/04/08 17:00:01 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/04/08 17:00:01 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/08 17:00:01 INFO ui.SparkUI: Stopped Spark web UI at http://10.0.2.15:4040
18/04/08 17:00:01 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/04/08 17:00:01 INFO storage.MemoryStore: MemoryStore cleared
18/04/08 17:00:01 INFO storage.BlockManager: BlockManager stopped
18/04/08 17:00:01 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
18/04/08 17:00:01 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/04/08 17:00:01 INFO spark.SparkContext: Successfully stopped SparkContext
18/04/08 17:00:01 INFO util.ShutdownHookManager: Shutdown hook called
18/04/08 17:00:01 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-6bdf5304-d1ff-409f-aa20-3e92f39e0106
18/04/08 17:00:01 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
18/04/08 17:00:01 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
[cloudera@quickstart ~]$ 
[cloudera@quickstart ~]$ hadoop fs -get /user/cloudera/project/output_l* /home/cloudera/Desktop/youtube-new/
