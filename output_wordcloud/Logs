[cloudera@quickstart ~]$ hadoop fs -put /home/cloudera/Desktop/youtube-new/Cleaned/* /user/cloudera/project/input
[cloudera@quickstart ~]$ 
[cloudera@quickstart ~]$ spark-submit --master local[*] --deploy-mode client --class com.cs267.youtube.util.WordCloudDriver /home/cloudera/Desktop/youtube-new/Youtube.jar /user/cloudera/project/input/ /user/cloudera/project/output
18/04/07 21:26:32 INFO spark.SparkContext: Running Spark version 1.6.0
18/04/07 21:26:37 INFO spark.SecurityManager: Changing view acls to: cloudera
18/04/07 21:26:37 INFO spark.SecurityManager: Changing modify acls to: cloudera
18/04/07 21:26:37 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(cloudera); users with modify permissions: Set(cloudera)
18/04/07 21:26:39 INFO util.Utils: Successfully started service 'sparkDriver' on port 57775.
18/04/07 21:26:41 INFO slf4j.Slf4jLogger: Slf4jLogger started
18/04/07 21:26:41 INFO Remoting: Starting remoting
18/04/07 21:26:42 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.0.2.15:43033]
18/04/07 21:26:42 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@10.0.2.15:43033]
18/04/07 21:26:42 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 43033.
18/04/07 21:26:42 INFO spark.SparkEnv: Registering MapOutputTracker
18/04/07 21:26:43 INFO spark.SparkEnv: Registering BlockManagerMaster
18/04/07 21:26:43 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-2239d1b0-7a50-4ecc-97cb-e32543937a0d
18/04/07 21:26:43 INFO storage.MemoryStore: MemoryStore started with capacity 530.3 MB
18/04/07 21:26:43 INFO spark.SparkEnv: Registering OutputCommitCoordinator
18/04/07 21:26:44 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
18/04/07 21:26:45 INFO ui.SparkUI: Started SparkUI at http://10.0.2.15:4040
18/04/07 21:26:45 INFO spark.SparkContext: Added JAR file:/home/cloudera/Desktop/youtube-new/Youtube.jar at spark://10.0.2.15:57775/jars/Youtube.jar with timestamp 1523161605680
18/04/07 21:26:46 INFO executor.Executor: Starting executor ID driver on host localhost
18/04/07 21:26:46 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49586.
18/04/07 21:26:46 INFO netty.NettyBlockTransferService: Server created on 49586
18/04/07 21:26:46 INFO storage.BlockManager: external shuffle service port = 7337
18/04/07 21:26:46 INFO storage.BlockManagerMaster: Trying to register BlockManager
18/04/07 21:26:47 INFO storage.BlockManagerMasterEndpoint: Registering block manager localhost:49586 with 530.3 MB RAM, BlockManagerId(driver, localhost, 49586)
18/04/07 21:26:47 INFO storage.BlockManagerMaster: Registered BlockManager
18/04/07 21:26:54 INFO scheduler.EventLoggingListener: Logging events to hdfs://quickstart.cloudera:8020/user/spark/applicationHistory/local-1523161606445
18/04/07 21:26:55 INFO spark.SparkContext: Registered listener com.cloudera.spark.lineage.ClouderaNavigatorListener
18/04/07 21:26:58 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 209.1 KB, free 530.1 MB)
18/04/07 21:26:59 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.3 KB, free 530.1 MB)
18/04/07 21:26:59 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49586 (size: 25.3 KB, free: 530.3 MB)
18/04/07 21:26:59 INFO spark.SparkContext: Created broadcast 0 from textFile at WordCloudDriver.java:24
18/04/07 21:27:01 INFO mapred.FileInputFormat: Total input paths to process : 5
18/04/07 21:27:01 INFO spark.SparkContext: Starting job: first at WordCloudDriver.java:25
18/04/07 21:27:02 INFO scheduler.DAGScheduler: Got job 0 (first at WordCloudDriver.java:25) with 1 output partitions
18/04/07 21:27:02 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (first at WordCloudDriver.java:25)
18/04/07 21:27:02 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/04/07 21:27:02 INFO scheduler.DAGScheduler: Missing parents: List()
18/04/07 21:27:02 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (/user/cloudera/project/input/ MapPartitionsRDD[1] at textFile at WordCloudDriver.java:24), which has no missing parents
18/04/07 21:27:02 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 530.0 MB)
18/04/07 21:27:02 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1847.0 B, free 530.0 MB)
18/04/07 21:27:02 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49586 (size: 1847.0 B, free: 530.3 MB)
18/04/07 21:27:02 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1004
18/04/07 21:27:02 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (/user/cloudera/project/input/ MapPartitionsRDD[1] at textFile at WordCloudDriver.java:24) (first 15 tasks are for partitions Vector(0))
18/04/07 21:27:02 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/04/07 21:27:03 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 2228 bytes)
18/04/07 21:27:03 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
18/04/07 21:27:03 INFO executor.Executor: Fetching spark://10.0.2.15:57775/jars/Youtube.jar with timestamp 1523161605680
18/04/07 21:27:03 INFO spark.ExecutorAllocationManager: New executor driver has registered (new total is 1)
18/04/07 21:27:03 INFO util.Utils: Fetching spark://10.0.2.15:57775/jars/Youtube.jar to /tmp/spark-67c6dd3f-adf9-4c2a-b7fc-f2d0a094c754/userFiles-0e28cc82-22a2-4167-a1e9-9df02327a9ae/fetchFileTemp356552983272756123.tmp
18/04/07 21:27:07 INFO executor.Executor: Adding file:/tmp/spark-67c6dd3f-adf9-4c2a-b7fc-f2d0a094c754/userFiles-0e28cc82-22a2-4167-a1e9-9df02327a9ae/Youtube.jar to class loader
18/04/07 21:27:08 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/project/input/CAvideos-csv.csv:0+15215710
18/04/07 21:27:09 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
18/04/07 21:27:09 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
18/04/07 21:27:09 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
18/04/07 21:27:09 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
18/04/07 21:27:09 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
18/04/07 21:27:52 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 2205 bytes result sent to driver
18/04/07 21:27:55 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 51662 ms on localhost (executor driver) (1/1)
18/04/07 21:27:57 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/04/07 21:27:59 INFO scheduler.DAGScheduler: ResultStage 0 (first at WordCloudDriver.java:25) finished in 56.105 s
18/04/07 21:28:02 INFO scheduler.DAGScheduler: Job 0 finished: first at WordCloudDriver.java:25, took 60.320045 s
18/04/07 21:28:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/04/07 21:28:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/04/07 21:28:11 INFO spark.SparkContext: Starting job: saveAsTextFile at WordCloudDriver.java:36
18/04/07 21:28:13 INFO scheduler.DAGScheduler: Registering RDD 4 (mapToPair at SparkWordCloud.java:46)
18/04/07 21:28:13 INFO scheduler.DAGScheduler: Got job 1 (saveAsTextFile at WordCloudDriver.java:36) with 5 output partitions
18/04/07 21:28:13 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (saveAsTextFile at WordCloudDriver.java:36)
18/04/07 21:28:13 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/04/07 21:28:13 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/04/07 21:28:13 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[4] at mapToPair at SparkWordCloud.java:46), which has no missing parents
18/04/07 21:28:13 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.4 KB, free 530.0 MB)
18/04/07 21:28:13 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.9 KB, free 530.0 MB)
18/04/07 21:28:13 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49586 (size: 2.9 KB, free: 530.3 MB)
18/04/07 21:28:13 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004
18/04/07 21:28:13 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[4] at mapToPair at SparkWordCloud.java:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/07 21:28:13 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
18/04/07 21:28:13 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 2217 bytes)
18/04/07 21:28:13 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, ANY, 2217 bytes)
18/04/07 21:28:13 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1)
18/04/07 21:28:13 INFO executor.Executor: Running task 1.0 in stage 1.0 (TID 2)
18/04/07 21:28:13 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/project/input/CAvideos-csv.csv:0+15215710
18/04/07 21:28:13 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/project/input/DEvideos-csv.csv:0+43594992
18/04/07 21:28:16 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:28:16 WARN spark.ExecutorAllocationManager: Unable to reach the cluster manager to request 2 total executors!
18/04/07 21:28:16 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:28:16 WARN spark.ExecutorAllocationManager: Unable to reach the cluster manager to request 3 total executors!
18/04/07 21:28:16 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:28:16 WARN spark.ExecutorAllocationManager: Unable to reach the cluster manager to request 4 total executors!
18/04/07 21:28:17 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:28:17 WARN spark.ExecutorAllocationManager: Unable to reach the cluster manager to request 5 total executors!
18/04/07 21:28:35 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on localhost:49586 in memory (size: 1847.0 B, free: 530.3 MB)
18/04/07 21:28:36 INFO spark.ContextCleaner: Cleaned accumulator 1
18/04/07 21:28:42 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 2240 bytes result sent to driver
18/04/07 21:28:42 INFO executor.Executor: Finished task 1.0 in stage 1.0 (TID 2). 2240 bytes result sent to driver
18/04/07 21:28:43 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, ANY, 2217 bytes)
18/04/07 21:28:43 INFO executor.Executor: Running task 2.0 in stage 1.0 (TID 3)
18/04/07 21:28:43 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, ANY, 2217 bytes)
18/04/07 21:28:43 INFO executor.Executor: Running task 3.0 in stage 1.0 (TID 4)
18/04/07 21:28:43 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/project/input/GBvideos-csv.csv:0+38970381
18/04/07 21:28:43 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/project/input/FRvideos-csv.csv:0+34652058
18/04/07 21:28:44 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 30776 ms on localhost (executor driver) (1/5)
18/04/07 21:28:44 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 30772 ms on localhost (executor driver) (2/5)
18/04/07 21:28:45 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:29:18 INFO executor.Executor: Finished task 2.0 in stage 1.0 (TID 3). 2240 bytes result sent to driver
18/04/07 21:29:18 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5, localhost, executor driver, partition 4, ANY, 2217 bytes)
18/04/07 21:29:18 INFO executor.Executor: Running task 4.0 in stage 1.0 (TID 5)
18/04/07 21:29:18 INFO executor.Executor: Finished task 3.0 in stage 1.0 (TID 4). 2240 bytes result sent to driver
18/04/07 21:29:18 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 34662 ms on localhost (executor driver) (3/5)
18/04/07 21:29:18 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 34765 ms on localhost (executor driver) (4/5)
18/04/07 21:29:18 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:29:18 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/project/input/USvideos-csv.csv:0+42174771
18/04/07 21:29:31 INFO executor.Executor: Finished task 4.0 in stage 1.0 (TID 5). 2240 bytes result sent to driver
18/04/07 21:29:32 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 14837 ms on localhost (executor driver) (5/5)
18/04/07 21:29:32 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/04/07 21:29:32 INFO scheduler.DAGScheduler: ShuffleMapStage 1 (mapToPair at SparkWordCloud.java:46) finished in 79.238 s
18/04/07 21:29:32 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:29:33 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/04/07 21:29:33 INFO scheduler.DAGScheduler: running: Set()
18/04/07 21:29:33 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 2)
18/04/07 21:29:33 INFO scheduler.DAGScheduler: failed: Set()
18/04/07 21:29:33 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[6] at saveAsTextFile at WordCloudDriver.java:36), which has no missing parents
18/04/07 21:29:35 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 78.6 KB, free 530.0 MB)
18/04/07 21:29:35 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:29:35 WARN spark.ExecutorAllocationManager: Unable to reach the cluster manager to request 2 total executors!
18/04/07 21:29:35 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 28.4 KB, free 529.9 MB)
18/04/07 21:29:35 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:49586 (size: 28.4 KB, free: 530.2 MB)
18/04/07 21:29:35 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004
18/04/07 21:29:35 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at saveAsTextFile at WordCloudDriver.java:36) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/07 21:29:35 INFO scheduler.TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
18/04/07 21:29:36 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 1944 bytes)
18/04/07 21:29:36 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 7, localhost, executor driver, partition 1, NODE_LOCAL, 1944 bytes)
18/04/07 21:29:36 INFO executor.Executor: Running task 0.0 in stage 2.0 (TID 6)
18/04/07 21:29:36 INFO executor.Executor: Running task 1.0 in stage 2.0 (TID 7)
18/04/07 21:29:36 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:29:36 WARN spark.ExecutorAllocationManager: Unable to reach the cluster manager to request 3 total executors!
18/04/07 21:29:37 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:29:37 WARN spark.ExecutorAllocationManager: Unable to reach the cluster manager to request 4 total executors!
18/04/07 21:29:38 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:29:38 WARN spark.ExecutorAllocationManager: Unable to reach the cluster manager to request 5 total executors!
18/04/07 21:29:41 INFO storage.ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
18/04/07 21:29:41 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 711 ms
18/04/07 21:29:41 INFO storage.ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
18/04/07 21:29:41 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1179 ms
18/04/07 21:30:23 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/04/07 21:30:25 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/04/07 21:30:25 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/04/07 21:30:25 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/04/07 21:31:07 INFO output.FileOutputCommitter: Saved output of task 'attempt_201804072128_0002_m_000001_7' to hdfs://quickstart.cloudera:8020/user/cloudera/project/output_wordcloud/_temporary/0/task_201804072128_0002_m_000001
18/04/07 21:31:07 INFO output.FileOutputCommitter: Saved output of task 'attempt_201804072128_0002_m_000000_6' to hdfs://quickstart.cloudera:8020/user/cloudera/project/output_wordcloud/_temporary/0/task_201804072128_0002_m_000000
18/04/07 21:31:07 INFO mapred.SparkHadoopMapRedUtil: attempt_201804072128_0002_m_000000_6: Committed
18/04/07 21:31:07 INFO mapred.SparkHadoopMapRedUtil: attempt_201804072128_0002_m_000001_7: Committed
18/04/07 21:31:08 INFO executor.Executor: Finished task 1.0 in stage 2.0 (TID 7). 2038 bytes result sent to driver
18/04/07 21:31:08 INFO executor.Executor: Finished task 0.0 in stage 2.0 (TID 6). 2038 bytes result sent to driver
18/04/07 21:31:08 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 2.0 (TID 8, localhost, executor driver, partition 2, NODE_LOCAL, 1944 bytes)
18/04/07 21:31:08 INFO executor.Executor: Running task 2.0 in stage 2.0 (TID 8)
18/04/07 21:31:08 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 2.0 (TID 9, localhost, executor driver, partition 3, NODE_LOCAL, 1944 bytes)
18/04/07 21:31:08 INFO executor.Executor: Running task 3.0 in stage 2.0 (TID 9)
18/04/07 21:31:08 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 6) in 92889 ms on localhost (executor driver) (1/5)
18/04/07 21:31:08 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 7) in 92573 ms on localhost (executor driver) (2/5)
18/04/07 21:31:08 INFO storage.ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
18/04/07 21:31:08 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
18/04/07 21:31:09 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:31:09 INFO storage.ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
18/04/07 21:31:09 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/07 21:31:16 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/04/07 21:31:16 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/04/07 21:31:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/04/07 21:31:17 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/04/07 21:31:24 INFO output.FileOutputCommitter: Saved output of task 'attempt_201804072128_0002_m_000003_9' to hdfs://quickstart.cloudera:8020/user/cloudera/project/output_wordcloud/_temporary/0/task_201804072128_0002_m_000003
18/04/07 21:31:24 INFO mapred.SparkHadoopMapRedUtil: attempt_201804072128_0002_m_000003_9: Committed
18/04/07 21:31:24 INFO executor.Executor: Finished task 3.0 in stage 2.0 (TID 9). 2052 bytes result sent to driver
18/04/07 21:31:24 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 2.0 (TID 10, localhost, executor driver, partition 4, NODE_LOCAL, 1944 bytes)
18/04/07 21:31:24 INFO executor.Executor: Running task 4.0 in stage 2.0 (TID 10)
18/04/07 21:31:24 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 2.0 (TID 9) in 15693 ms on localhost (executor driver) (3/5)
18/04/07 21:31:24 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:31:24 INFO storage.ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
18/04/07 21:31:24 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/07 21:31:30 INFO output.FileOutputCommitter: Saved output of task 'attempt_201804072128_0002_m_000002_8' to hdfs://quickstart.cloudera:8020/user/cloudera/project/output_wordcloud/_temporary/0/task_201804072128_0002_m_000002
18/04/07 21:31:30 INFO mapred.SparkHadoopMapRedUtil: attempt_201804072128_0002_m_000002_8: Committed
18/04/07 21:31:30 INFO executor.Executor: Finished task 2.0 in stage 2.0 (TID 8). 2052 bytes result sent to driver
18/04/07 21:31:30 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 2.0 (TID 8) in 22050 ms on localhost (executor driver) (4/5)
18/04/07 21:31:30 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:31:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/04/07 21:31:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/04/07 21:31:32 INFO output.FileOutputCommitter: Saved output of task 'attempt_201804072128_0002_m_000004_10' to hdfs://quickstart.cloudera:8020/user/cloudera/project/output_wordcloud/_temporary/0/task_201804072128_0002_m_000004
18/04/07 21:31:32 INFO mapred.SparkHadoopMapRedUtil: attempt_201804072128_0002_m_000004_10: Committed
18/04/07 21:31:32 INFO executor.Executor: Finished task 4.0 in stage 2.0 (TID 10). 2052 bytes result sent to driver
18/04/07 21:31:33 INFO scheduler.DAGScheduler: ResultStage 2 (saveAsTextFile at WordCloudDriver.java:36) finished in 117.246 s
18/04/07 21:31:33 INFO scheduler.DAGScheduler: Job 1 finished: saveAsTextFile at WordCloudDriver.java:36, took 201.366400 s
18/04/07 21:31:33 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 2.0 (TID 10) in 8805 ms on localhost (executor driver) (5/5)
18/04/07 21:31:33 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/04/07 21:31:33 WARN spark.SparkContext: Requesting executors is only supported in coarse-grained mode
18/04/07 21:31:33 INFO ui.SparkUI: Stopped Spark web UI at http://10.0.2.15:4040
18/04/07 21:31:34 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on localhost:49586 in memory (size: 28.4 KB, free: 530.3 MB)
18/04/07 21:31:34 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/04/07 21:31:34 INFO storage.MemoryStore: MemoryStore cleared
18/04/07 21:31:34 INFO storage.BlockManager: BlockManager stopped
18/04/07 21:31:34 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
18/04/07 21:31:34 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/04/07 21:31:34 INFO spark.SparkContext: Successfully stopped SparkContext
18/04/07 21:31:34 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
18/04/07 21:31:35 INFO util.ShutdownHookManager: Shutdown hook called
18/04/07 21:31:35 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
18/04/07 21:31:35 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-67c6dd3f-adf9-4c2a-b7fc-f2d0a094c754
[cloudera@quickstart ~]$ hadoop fs -get /user/cloudera/project/output_*/ /home/cloudera/Desktop/youtube-new/
